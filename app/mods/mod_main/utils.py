import requests
from bs4 import BeautifulSoup
from datetime import datetime
from datetime import date
from app.mods.mod_main.databasePSQL import PSQLDatabase
from googlesearch import search
import sqlite3


def createCVEdb(new_cve):
    db = PSQLDatabase()
    db.query("SELECT CVE_id from CVES where CVE_id = '"+new_cve+"';")
    if not db.cursor.fetchone():
        req = requests.get("https://nvd.nist.gov/vuln/detail/"+new_cve)
        soup = BeautifulSoup(req.content, 'html.parser')
        NVD_Description = soup.find("p", {"data-testid" : "vuln-description"}).getText().replace("'", "")
        NVD_Published_Date = soup.find("span", {"data-testid" : "vuln-published-on"}).getText()
        NVD_Published_Date = datetime.strptime(NVD_Published_Date, '%m/%d/%Y').strftime('%Y-%m-%d')
        print("Exploit published on: "+ str(NVD_Published_Date))

        sql = f"INSERT INTO CVES (CVE_id, Description, Publised_Date) VALUES ('{new_cve}','{NVD_Description}','{NVD_Published_Date}') ON CONFLICT DO NOTHING;"
        db.query(sql)
        db.conn.commit()

    else:
        print("El cve ya existe")

    db.close()
    return "OK"


def deleteCVEdb(cve):
    db = PSQLDatabase()
    db.query("DELETE from CVES where CVE_id = '"+cve+"';")
    db.conn.commit()
    db.close()
    return "OK"


def loadCVEs():
    db = PSQLDatabase()
    db.query("SELECT * FROM cves ORDER BY cve_id ASC;")
    data = db.cursor.fetchall()
    db.close()
    # return json.dumps(data)
    return data


def searchByCVE(cve, mode):
    db = PSQLDatabase()
    db.query("SELECT description FROM cves WHERE cve_id = '"+cve+"';")
    data = db.cursor.fetchall()
    db.close()
    if mode == "description":
        return data[0][0]


def getGoogle(cve):
    links = ""
    for j in search(cve, tld="co.in", num=20, stop=20, pause=2):
        links += j+","
    links = links[:-1]

    with sqlite3.connect('cve_s3arch.db') as conn:
        cursor = conn.cursor()
        cursor.execute('UPDATE cves SET googleLinks=? WHERE cve=?;', [links, cve])
        data = cursor.fetchall()

    return links
