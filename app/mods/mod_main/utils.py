import requests
from bs4 import BeautifulSoup
from datetime import datetime
from datetime import date
import twint
from app.mods.mod_main.databasePSQL import PSQLDatabase
from googlesearch import search
import sqlite3


def createCVEdb(new_cve):
    db = PSQLDatabase()
    db.query("SELECT CVE_id from CVES where CVE_id = '"+new_cve+"';")
    if not db.cursor.fetchone():
        req = requests.get("https://nvd.nist.gov/vuln/detail/"+new_cve)
        soup = BeautifulSoup(req.content, 'html.parser')
        NVD_Description = soup.find("p", {"data-testid" : "vuln-description"}).getText().replace("'", "")
        NVD_Published_Date = soup.find("span", {"data-testid" : "vuln-published-on"}).getText()
        NVD_Published_Date = datetime.strptime(NVD_Published_Date, '%m/%d/%Y').strftime('%Y-%m-%d')
        print("Exploit published on: "+ str(NVD_Published_Date))

        sql = f"INSERT INTO CVES (CVE_id, Description, Publised_Date) VALUES ('{new_cve}','{NVD_Description}','{NVD_Published_Date}') ON CONFLICT DO NOTHING;"
        db.query(sql)
        db.conn.commit()

    else:
        print("El cve ya existe")

    db.close()
    return "OK"


def deleteCVEdb(cve):
    db = PSQLDatabase()
    db.query("DELETE from CVES where CVE_id = '"+cve+"';")
    db.conn.commit()
    db.close()
    return "OK"


def loadCVEs():
    db = PSQLDatabase()
    db.query("SELECT * FROM cves ORDER BY cve_id ASC;")
    data = db.cursor.fetchall()
    db.close()
    # return json.dumps(data)
    return data


def searchByCVE(cve, mode):
    db = PSQLDatabase()
    db.query("SELECT description FROM cves WHERE cve_id = '"+cve+"';")
    data = db.cursor.fetchall()
    db.close()
    if mode == "description":
        return data[0][0]


def getTweets(cve):
    db = PSQLDatabase()
    db.query(f"SELECT publised_date from CVES where CVE_id = '{cve}'")
    NVD_Published_Date = db.cursor.fetchone()[0]

    tweets = []
    c = twint.Config()
    c.Search = cve
    c.Since = NVD_Published_Date
    c.Store_object = True
    c.Hide_output = True
    c.Filter_retweets = True
    c.Store_object_tweets_list = tweets

    twint.run.Search(c)

    for t in tweets:
        url_list = ','.join([u for u in t.urls ])
        santweet = t.tweet.replace("'","")
        sqlquery = f"""INSERT INTO TwitterTweets (CVE_id, tweet_id, tweet, Datestamp, retweet_count, Replies_Count, Likes_Count, URLs)
                        VALUES ('{cve}','{t.id}','{santweet}','{t.datestamp}','{t.retweets_count}','{t.replies_count}','{t.likes_count}','{url_list}')
                        ON CONFLICT (tweet_id)
                        DO UPDATE SET
                        retweet_count = excluded.retweet_count,
                        Replies_Count = excluded.Replies_Count,
                        Likes_Count = excluded.Likes_Count
                        ;"""
        print(sqlquery)
        db.query(sqlquery)
    db.conn.commit()
    db.close()
    return "OK"


def getGoogle(cve):
    links = ""
    for j in search(cve, tld="co.in", num=20, stop=20, pause=2):
        links += j+","
    links = links[:-1]

    with sqlite3.connect('cve_s3arch.db') as conn:
        cursor = conn.cursor()
        cursor.execute('UPDATE cves SET googleLinks=? WHERE cve=?;', [links, cve])
        data = cursor.fetchall()

    return links
