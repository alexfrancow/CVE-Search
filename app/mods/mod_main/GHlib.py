import json
from github import Github
import configparser
from datetime import datetime
from datetime import date
from app.mods.mod_main.databasePSQL import PSQLDatabase
import pandas as pd

def getRepos(cve):
    config = configparser.ConfigParser()
    try:
        config.read('./config.ini')
    except FileExistsError as err:
        print('File exists error: {0}', err)
        sys.exit(1)

    ACCESS_TOKEN = config['Github']['ACCESS_TOKEN']
    g = Github(ACCESS_TOKEN)
    db = PSQLDatabase()

    rate_limit = g.get_rate_limit()
    rate = rate_limit.search
    if rate.remaining == 0:
        print(f'You have 0/{rate.limit} API calls remaining. Reset time: {rate.reset}')
        return
    else:
        print(f'You have {rate.remaining}/{rate.limit} API calls remaining')

    # Search code
    query = f'"{cve}" in:file extension:py extension:ps1 extension:md extension:vbs extension:rb extension:pl extension:php extension:go extension:sh extension:bat extension:sql extension:exe extension:sln extension:txt'
    result_code = g.search_code(query, order='desc')

    for file in result_code:
        created_at = datetime.strptime(str(file.repository.created_at), '%Y-%m-%d %H:%M:%S').strftime('%Y-%m-%d')
        updated_at = datetime.strptime(str(file.repository.updated_at), '%Y-%m-%d %H:%M:%S').strftime('%Y-%m-%d')

        sqlquery = f"""INSERT INTO GithubRepos (CVE_id, repo_id, owner, created_at, updated_at, forks_count, stargazers_count, repository)
                       VALUES ('{cve}','{file.repository.id}', '{file.repository.owner.login}','{created_at}','{updated_at}','{file.repository.forks_count}','{file.repository.stargazers_count}','{file.repository.full_name}')
                       ON CONFLICT (repo_id)
                       DO UPDATE SET
                       forks_count = excluded.forks_count,
                       stargazers_count = excluded.stargazers_count,
                       updated_at = excluded.updated_at
                       ;"""
        db.query(sqlquery)
        sqlquery = f"""INSERT INTO GithubReposURLs (CVE_id, repo_id, name, download_url, sha1, date_add, epoch)
                       VALUES ('{cve}','{file.repository.id}', '{file.name}', '{file.download_url}', '{file.sha}', '{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}', '{int(datetime.now().timestamp())}')
                       ON CONFLICT (download_url)
                       DO UPDATE SET
                       sha1 = excluded.sha1
                       ;"""
        db.query(sqlquery)
    db.conn.commit()
    db.close()
    return "OK"


def reposJSON(cve):
    db = PSQLDatabase()
    sqlquery = f"""SELECT json_agg(to_json(d))
                   from (
                        select
                            repo_id, created_at, download_url, stargazers_count, forks_count
                        from githubrepos WHERE cve_id = '{cve}'
                   ) as d
                   ;"""

    sqlquery = f"""SELECT json_agg(to_json(d))
                   from (
                       SELECT repou.CVE_id, repou.download_url, repo.repository, repo.updated_at, repou.name, repou.sha1 
                       FROM GithubReposURLs as repou
                       INNER JOIN GithubRepos as repo ON repo.repo_id = repou.repo_id
                       WHERE repou.cve_id = '{cve}'
                       ORDER BY repo.updated_at DESC
                   ) as d
                   ;"""
    db.query(sqlquery)
    data_repo = db.cursor.fetchone()
    data_repo = data_repo[0]

    return json.dumps(data_repo)


def reposJSON_chart(cve):
    db = PSQLDatabase()
    sqlquery = f"""SELECT repo.updated_at, repou.name, repou.sha1
                   FROM GithubReposURLs as repou
                   INNER JOIN GithubRepos as repo ON repo.repo_id = repou.repo_id
                   WHERE repou.cve_id = '{cve}'
                   ;"""

    db.query(sqlquery)
    data_files = db.cursor.fetchall()
    df_files = pd.DataFrame(columns=['Date','File','SHA1'])
    for data in data_files:
        index = len(df_files)
        df_files.loc[index,'Date'] = data[0]
        df_files.loc[index,'File'] = data[1]
        df_files.loc[index,'SHA1'] = data[2]

    # Set Date to index
    df_files['datetime'] = pd.to_datetime(df_files['Date'])
    df_files = df_files.set_index('datetime')
    a = df_files.groupby('Date')['File'].apply(list)

    # MAX Files
    df_files = df_files.sort_values('Date').drop_duplicates(['Date'],keep='last').sort_index()
    df_files = df_files.sort_index()
    df_files['n_files'] = [len(c) for c in a.tolist()]
    df_files['all_files'] = [c for c in a.tolist()]

    data = {}
    # Dates
    data['dates'] = []
    for date in df_files['Date']:
        data['dates'].append(date)

    # Files Volume (n_files)
    data['files_volume'] = []
    for n_files in df_files['n_files']:
        data['files_volume'].append(n_files)

    print(data)
    db.close()
    return data

