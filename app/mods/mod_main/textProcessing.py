# Predict exploit
from joblib import dump, load
import re
import nltk
from nltk.tokenize import RegexpTokenizer, TweetTokenizer
from nltk.stem import WordNetLemmatizer
from nltk.stem import PorterStemmer
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.corpus import stopwords
import pandas as pd

nltk.download("stopwords", "models/stopwords")
nltk.data.path.append('models/stopwords/')
nltk.download("wordnet", "models/wordnet")
nltk.data.path.append('models/wordnet/')

class TWprocessing():
    def __init__(self):
        stop_words = set(stopwords.words('english'))
        stop_words_alexfrancow = ['http','2019','2018','cve','2020']
        self.gs_mnnb = load('models/TW_exploit_detect_NLP_Modelv1.joblib')

    def remove_URL(self, x):
        return re.sub(r"http\S+", "", x)

    def tokenize(self, x):
        tokenizer = TweetTokenizer()
        return tokenizer.tokenize(x.lower())

    def tokenize_remove_regex(self, x):
        listToStr = ' '.join([str(elem) for elem in x])
        tokenizer = RegexpTokenizer(r'http|2019|2018|cve|2020| |\.|,|:|;|!|\?|\(|\)|\||\+|\'|"|‘|’|“|”|\'|\’|…|\-|–|—|\$|&|\*|>|<|\/|\[|\]', gaps=True)
        return tokenizer.tokenize(listToStr)

    def stemmer(self, x):
        stemmer = PorterStemmer()
        return ' '.join([stemmer.stem(word) for word in x])

    def lemmatize(self, x):
        lemmatizer = WordNetLemmatizer()
        return ' '.join([lemmatizer.lemmatize(word) for word in x])

    def gen_pre(self, x):
        dfpre = pd.DataFrame({'Tweet': x}, index=[0])
        dfpre['Tweet'] = dfpre['Tweet'].map(self.remove_URL)
        dfpre['tokens'] = dfpre['Tweet'].map(self.tokenize)
        dfpre['tokens'] = dfpre['tokens'].map(self.tokenize_remove_regex)
        dfpre['lemma'] = dfpre['tokens'].map(self.lemmatize)
        dfpre['stems'] = dfpre['tokens'].map(self.stemmer)
        return self.gs_mnnb.predict(dfpre['stems'])

    def funcTWprocessing(self, df_Tweet_Tweet):
        predicts = df_Tweet_Tweet.map(self.gen_pre)
        preds = []
        for p in predicts:
            preds.append(p[0])
        return preds
